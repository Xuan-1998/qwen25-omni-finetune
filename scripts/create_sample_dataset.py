#!/usr/bin/env python3
"""
Create a sample dataset for Qwen 2.5 Omni fine-tuning
"""

import json
import os

def create_sample_dataset():
    """Create a sample multi-modal dataset for Qwen 2.5 Omni."""
    
    # Sample data for multi-modal fine-tuning
    sample_data = [
        {
            "input": "è¯·æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹ã€‚",
            "output": "è¿™æ˜¯ä¸€å¼ ç¾ä¸½çš„é£æ™¯å›¾ç‰‡ï¼Œå±•ç¤ºäº†è“å¤©ç™½äº‘ä¸‹çš„ç»¿è‰²å±±è„‰å’Œæ¸…æ¾ˆçš„æ¹–æ³Šã€‚å›¾ç‰‡æ„å›¾ä¼˜ç¾ï¼Œè‰²å½©ä¸°å¯Œï¼Œç»™äººä¸€ç§å®é™ç¥¥å’Œçš„æ„Ÿè§‰ã€‚",
            "image_path": "images/sample1.jpg"  # Optional: for multi-modal training
        },
        {
            "input": "è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "output": "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯æŒ‡è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æŠ€æœ¯ã€‚å®ƒåŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰å¤šä¸ªé¢†åŸŸã€‚AIå¯ä»¥å¸®åŠ©æˆ‘ä»¬è§£å†³å¤æ‚é—®é¢˜ï¼Œæé«˜å·¥ä½œæ•ˆç‡ï¼Œæ”¹å–„ç”Ÿæ´»è´¨é‡ã€‚",
            "image_path": None
        },
        {
            "input": "è¯·åˆ†æè¿™æ®µéŸ³é¢‘çš„å†…å®¹ã€‚",
            "output": "è¿™æ®µéŸ³é¢‘åŒ…å«äº†ä¸€æ®µæ¸…æ™°çš„å¯¹è¯ï¼Œè¯­é€Ÿé€‚ä¸­ï¼Œå‘éŸ³æ ‡å‡†ã€‚ä¸»è¦å†…å®¹æ¶‰åŠæŠ€æœ¯è®¨è®ºï¼Œè¯´è¯è€…è¡¨è¾¾äº†ä¸“ä¸šçš„è§‚ç‚¹å’Œå»ºè®®ã€‚",
            "audio_path": "audio/sample1.wav"  # Optional: for audio processing
        },
        {
            "input": "æ€»ç»“ä¸€ä¸‹è¿™ä¸ªè§†é¢‘çš„ä¸»è¦è§‚ç‚¹ã€‚",
            "output": "è¿™ä¸ªè§†é¢‘ä¸»è¦è®¨è®ºäº†å½“å‰æŠ€æœ¯å‘å±•çš„è¶‹åŠ¿ï¼Œå¼ºè°ƒäº†åˆ›æ–°å’Œåˆä½œçš„é‡è¦æ€§ã€‚æ¼”è®²è€…æå‡ºäº†å‡ ä¸ªå…³é”®å»ºè®®ï¼šæŒç»­å­¦ä¹ ã€æ‹¥æŠ±å˜åŒ–ã€å»ºç«‹å›¢é˜Ÿåˆä½œã€‚æ•´ä¸ªæ¼”è®²ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼ºã€‚",
            "video_path": "videos/sample1.mp4"  # Optional: for video processing
        },
        {
            "input": "å¸®æˆ‘å†™ä¸€ä¸ªPythonå‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚",
            "output": "```python\ndef fibonacci(n):\n    \"\"\"\n    è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹\n    \n    Args:\n        n (int): è¦è®¡ç®—çš„é¡¹æ•°\n    \n    Returns:\n        int: æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹\n    \"\"\"\n    if n <= 1:\n        return n\n    \n    a, b = 0, 1\n    for _ in range(2, n + 1):\n        a, b = b, a + b\n    \n    return b\n\n# ç¤ºä¾‹ç”¨æ³•\nprint(fibonacci(10))  # è¾“å‡º: 55\n```",
            "image_path": None
        },
        {
            "input": "è¯·ç¿»è¯‘è¿™å¥è¯ï¼š'Hello, how are you today?'",
            "output": "è¿™å¥è¯çš„ä¸­æ–‡ç¿»è¯‘æ˜¯ï¼š'ä½ å¥½ï¼Œä½ ä»Šå¤©æ€ä¹ˆæ ·ï¼Ÿ'",
            "image_path": None
        },
        {
            "input": "è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ ä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚",
            "output": "è¿‡æ‹Ÿåˆï¼ˆOverfittingï¼‰æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ä¸ªå¸¸è§é—®é¢˜ï¼ŒæŒ‡æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨æ–°çš„ã€æœªè§è¿‡çš„æ•°æ®ä¸Šè¡¨ç°è¾ƒå·®çš„ç°è±¡ã€‚\n\nä¸»è¦åŸå› åŒ…æ‹¬ï¼š\n1. æ¨¡å‹è¿‡äºå¤æ‚ï¼Œå‚æ•°è¿‡å¤š\n2. è®­ç»ƒæ•°æ®ä¸è¶³\n3. è®­ç»ƒæ—¶é—´è¿‡é•¿\n\nè§£å†³æ–¹æ³•ï¼š\n1. å¢åŠ è®­ç»ƒæ•°æ®\n2. ä½¿ç”¨æ­£åˆ™åŒ–æŠ€æœ¯\n3. å‡å°‘æ¨¡å‹å¤æ‚åº¦\n4. ä½¿ç”¨äº¤å‰éªŒè¯\n5. æ—©åœï¼ˆEarly Stoppingï¼‰",
            "image_path": None
        },
        {
            "input": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡ä¸­çš„æ•°å­¦å…¬å¼ã€‚",
            "output": "è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†ä¸€ä¸ªå¤æ‚çš„æ•°å­¦å…¬å¼ï¼Œçœ‹èµ·æ¥æ˜¯ä¸€ä¸ªç§¯åˆ†è¡¨è¾¾å¼ã€‚å…¬å¼æ¶‰åŠä¸‰è§’å‡½æ•°å’ŒæŒ‡æ•°å‡½æ•°ï¼Œå¯èƒ½ç”¨äºæè¿°æŸç§ç‰©ç†ç°è±¡æˆ–æ•°å­¦å…³ç³»ã€‚å…·ä½“çš„æ¨å¯¼è¿‡ç¨‹éœ€è¦æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚",
            "image_path": "images/math_formula.jpg"
        }
    ]
    
    # Create data directory if it doesn't exist
    os.makedirs("./data", exist_ok=True)
    
    # Save dataset
    output_path = "./data/train_data.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(sample_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Sample dataset created at {output_path}")
    print(f"ğŸ“Š Dataset contains {len(sample_data)} samples")
    print("ğŸ“ Dataset format includes:")
    print("  - Text-only conversations")
    print("  - Multi-modal inputs (image, audio, video)")
    print("  - Code generation examples")
    print("  - Translation tasks")
    print("  - Technical explanations")
    
    # Create additional dataset files
    create_validation_dataset()
    create_test_dataset()
    
    return output_path

def create_validation_dataset():
    """Create validation dataset."""
    validation_data = [
        {
            "input": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
            "output": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚æ·±åº¦å­¦ä¹ èƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼å’Œç‰¹å¾ï¼Œåœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³å¤„ç†ã€è‡ªç„¶è¯­è¨€ç†è§£ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚",
            "image_path": None
        },
        {
            "input": "å†™ä¸€ä¸ªç®€å•çš„æ’åºç®—æ³•ã€‚",
            "output": "```python\ndef bubble_sort(arr):\n    \"\"\"\n    å†’æ³¡æ’åºç®—æ³•\n    \"\"\"\n    n = len(arr)\n    for i in range(n):\n        for j in range(0, n - i - 1):\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    return arr\n\n# æµ‹è¯•\nnumbers = [64, 34, 25, 12, 22, 11, 90]\nsorted_numbers = bubble_sort(numbers)\nprint(sorted_numbers)  # [11, 12, 22, 25, 34, 64, 90]\n```",
            "image_path": None
        }
    ]
    
    with open("./data/validation_data.json", 'w', encoding='utf-8') as f:
        json.dump(validation_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… Validation dataset created")

def create_test_dataset():
    """Create test dataset."""
    test_data = [
        {
            "input": "è¯·åˆ†æè¿™ä¸ªä»£ç çš„æ—¶é—´å¤æ‚åº¦ã€‚",
            "output": "è¿™ä¸ªä»£ç çš„æ—¶é—´å¤æ‚åº¦æ˜¯O(nÂ²)ã€‚å¤–å±‚å¾ªç¯æ‰§è¡Œnæ¬¡ï¼Œå†…å±‚å¾ªç¯åœ¨æœ€åæƒ…å†µä¸‹ä¹Ÿæ‰§è¡Œnæ¬¡ï¼Œå› æ­¤æ€»ä½“æ—¶é—´å¤æ‚åº¦ä¸ºO(nÂ²)ã€‚",
            "image_path": None
        },
        {
            "input": "è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯åŒºå—é“¾æŠ€æœ¯ï¼Ÿ",
            "output": "åŒºå—é“¾æ˜¯ä¸€ç§åˆ†å¸ƒå¼è´¦æœ¬æŠ€æœ¯ï¼Œå®ƒé€šè¿‡å¯†ç å­¦æ–¹æ³•å°†æ•°æ®å—æŒ‰æ—¶é—´é¡ºåºè¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªä¸å¯ç¯¡æ”¹çš„é“¾æ¡ã€‚æ¯ä¸ªåŒºå—åŒ…å«å‰ä¸€ä¸ªåŒºå—çš„å“ˆå¸Œå€¼ï¼Œç¡®ä¿äº†æ•°æ®çš„å®‰å…¨æ€§å’Œå®Œæ•´æ€§ã€‚åŒºå—é“¾æŠ€æœ¯å¹¿æ³›åº”ç”¨äºæ•°å­—è´§å¸ã€æ™ºèƒ½åˆçº¦ã€ä¾›åº”é“¾ç®¡ç†ç­‰é¢†åŸŸã€‚",
            "image_path": None
        }
    ]
    
    with open("./data/test_data.json", 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… Test dataset created")

if __name__ == "__main__":
    create_sample_dataset()
